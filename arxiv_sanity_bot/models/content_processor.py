"""Lightweight content processing using DeepSeek API."""

import json
import os
from typing import Any

from arxiv_sanity_bot.logger import get_logger
from arxiv_sanity_bot.models.openai import OpenAI
from arxiv_sanity_bot.schemas import ContentItem
from arxiv_sanity_bot.config import CONTENT_KEYWORDS

logger = get_logger(__name__)


class ContentProcessor:
    """Process content with LLM for summaries and insights (lightweight, token-efficient)."""

    def __init__(self):
        self._client: OpenAI | None = None
        self._provider = os.environ.get("LLM_PROVIDER", "openai").lower()

    def _get_client(self) -> OpenAI:
        """Lazy initialization of OpenAI client."""
        if self._client is None:
            self._client = OpenAI()
        return self._client

    def _fallback_scoring(
        self, contents: list[dict[str, Any]]
    ) -> list[dict[str, Any]]:
        """
        Fallback scoring when AI scoring fails.

        Uses rule-based scoring based on engagement metrics.
        Base score: 5, with bonuses for stars and content type.

        Args:
            contents: List of content dicts with type, title, stars, etc.

        Returns:
            Contents with score, tag, and reason added.
        """
        results = []
        for item in contents:
            score = 5  # Base score
            content_type = item.get("type", "")
            stars = item.get("stars", 0) or 0

            # GitHub stars bonus
            if content_type == "github":
                if stars > 500:
                    score += 3
                elif stars > 100:
                    score += 1

            # arXiv papers get a small bonus for academic depth
            if content_type == "arxiv":
                score += 1

            # Cap at 10
            score = min(score, 10)

            # Assign tag based on score
            if score >= 8:
                tag = "ğŸ”¥ å¿…çœ‹"
            elif score >= 5:
                tag = "ğŸ“– æ·±åº¦"
            else:
                tag = "âš¡ é€Ÿè§ˆ"

            # Use first 40 chars of description as reason
            description = item.get("description", "")
            reason = description[:40] + "..." if len(description) > 40 else description
            if not reason:
                reason = "å€¼å¾—å…³æ³¨çš„å†…å®¹"

            # Copy and add scoring fields
            item_copy = item.copy()
            item_copy["score"] = score
            item_copy["tag"] = tag
            item_copy["reason"] = reason
            results.append(item_copy)

        logger.warning(f"Fallback scoring applied to {len(contents)} items (AI scoring failed)")
        return results

    def score_and_tag_contents(
        self, contents: list[dict[str, Any]]
    ) -> list[dict[str, Any]]:
        """
        Score and tag content items using AI or fallback rules.

        Uses DeepSeek AI to score each item 1-10 based on:
        - 30% popularity (stars, citations)
        - 30% novelty (new concepts/projects)
        - 40% practical value (usable tools > theory)

        Tags: ğŸ”¥å¿…çœ‹ (â‰¥8), ğŸ“–æ·±åº¦ (5-7), âš¡é€Ÿè§ˆ (<5)

        Args:
            contents: List of content dicts with type, title, stars, description

        Returns:
            Contents with score, tag, and reason fields added
        """
        if not contents:
            return []

        # Build indexed content list for AI
        content_lines = []
        for i, item in enumerate(contents, 1):
            content_type = item.get("type", "unknown")
            title = item.get("title", "")
            stars = item.get("stars", "")
            description = item.get("description", "")[:200]  # Truncate for tokens
            content_lines.append(
                f"{i}. [{content_type}] {title} (stars: {stars})\n   {description}"
            )

        content_text = "\n\n".join(content_lines)

        history = [
            {
                "role": "system",
                "content": (
                    "ä½ æ˜¯ AI èµ„è®¯ç­›é€‰åŠ©æ‰‹ã€‚è¯·å¯¹ä»¥ä¸‹å†…å®¹é€æ¡æ‰“åˆ†å’Œæ ‡ç­¾ã€‚\n\n"
                    "æ‰“åˆ†è§„åˆ™ï¼ˆ1-10ï¼‰ï¼š\n"
                    "- çƒ­åº¦ï¼ˆstaræ•°ã€å¼•ç”¨é‡ï¼‰å  30%\n"
                    "- æ–°é¢–åº¦ï¼ˆé¦–æ¬¡å‡ºç°çš„æ–°é¡¹ç›®/æ¦‚å¿µï¼‰å  30%\n"
                    "- å®ç”¨ä»·å€¼ï¼ˆå¯ç›´æ¥ä½¿ç”¨çš„å·¥å…· > çº¯ç†è®ºç ”ç©¶ï¼‰å  40%\n\n"
                    "æ ‡ç­¾è§„åˆ™ï¼š\n"
                    "- ğŸ”¥ å¿…çœ‹ï¼šâ‰¥ 8 åˆ†ï¼Œé‡å¤§çªç ´æˆ–è¶…é«˜çƒ­åº¦\n"
                    "- ğŸ“– æ·±åº¦ï¼š5-7 åˆ†ï¼Œå€¼å¾—æ·±å…¥äº†è§£\n"
                    "- âš¡ é€Ÿè§ˆï¼š< 5 åˆ†ï¼Œäº†è§£å³å¯\n\n"
                    "è¾“å‡ºæ ¼å¼ï¼ˆä¸¥æ ¼ JSONï¼‰ï¼š\n"
                    '[{"index": 1, "score": 8, "tag": "ğŸ”¥ å¿…çœ‹", "reason": "ä¸€å¥è¯æ¨èç†ç”±"}, ...]'
                ),
            },
            {
                "role": "user",
                "content": f"è¯·å¯¹ä»¥ä¸‹å†…å®¹é€æ¡æ‰“åˆ†ï¼ˆå…± {len(contents)} æ¡ï¼‰ï¼š\n\n{content_text}\n\nè¯·è¿”å› JSON æ•°ç»„ï¼š",
            },
        ]

        try:
            response = self._get_client()._call_openai(history)

            # Parse JSON response
            try:
                # Extract JSON from response (handle markdown code blocks)
                json_str = response.strip()
                if "```json" in json_str:
                    parts = json_str.split("```json")
                    if len(parts) > 1:
                        inner = parts[1]
                        json_str = inner.split("```")[0] if "```" in inner else inner
                elif "```" in json_str:
                    parts = json_str.split("```")
                    if len(parts) > 1:
                        json_str = parts[1]

                scores_data = json.loads(json_str.strip())

                # Validate and apply scores
                if isinstance(scores_data, list) and len(scores_data) == len(contents):
                    results = []
                    for i, (item, score_info) in enumerate(zip(contents, scores_data), 1):
                        # Validate index matches expected position
                        if score_info.get("index") != i:
                            logger.debug(f"Index mismatch at position {i}: expected {i}, got {score_info.get('index')}")
                        item_copy = item.copy()
                        item_copy["score"] = score_info.get("score", 5)
                        item_copy["tag"] = score_info.get("tag", "ğŸ“– æ·±åº¦")
                        item_copy["reason"] = score_info.get(
                            "reason", "å€¼å¾—å…³æ³¨çš„å†…å®¹"
                        )
                        results.append(item_copy)
                    return results
                else:
                    logger.warning(
                        f"AI scoring returned invalid format or length mismatch, using fallback"
                    )
                    return self._fallback_scoring(contents)

            except (json.JSONDecodeError, KeyError) as e:
                logger.warning(f"Failed to parse AI scoring response: {e}")
                return self._fallback_scoring(contents)

        except Exception as e:
            logger.warning(f"AI scoring API call failed: {e}")
            return self._fallback_scoring(contents)

    def generate_daily_insight(self, top3_context: str) -> str:
        """
        Generate a brief daily insight based on top 3 content items.

        Focuses on the most important items only, keeping output under 80 chars.

        Args:
            top3_context: Formatted string of top 3 content items by importance

        Returns:
            Brief insight string (max ~80 chars)
        """
        if not top3_context:
            return "ä»Šæ—¥ AI é¢†åŸŸç¨³æ­¥å‘å±•ã€‚"

        history = [
            {
                "role": "system",
                "content": (
                    "ä½ æ˜¯ AI æ™¨æŠ¥ç¼–è¾‘ã€‚è¯·ç”Ÿæˆä»Šæ—¥æ´å¯Ÿï¼Œè¦æ±‚ï¼š\n"
                    "1. ç¬¬ä¸€å¥ï¼šä»Šå¤©æœ€é‡è¦çš„ä¸€ä»¶äº‹ï¼ˆåŠ ç²—å¤„ç†ï¼‰\n"
                    "2. ç¬¬äºŒå¥ï¼šä¸ºä»€ä¹ˆé‡è¦ / å¯¹å¼€å‘è€…æ„å‘³ç€ä»€ä¹ˆ\n"
                    "3. ç¬¬ä¸‰å¥ï¼ˆå¯é€‰ï¼‰ï¼šå¦ä¸€ä¸ªå€¼å¾—å…³æ³¨çš„åŠ¨å‘\n\n"
                    "è§„åˆ™ï¼š\n"
                    "- æ€»å…±ä¸è¶…è¿‡ 80 å­—\n"
                    '- ä¸è¦ç”¨"ä»Šæ—¥AIé¢†åŸŸ"è¿™æ ·çš„å¥—è¯å¼€å¤´\n'
                    "- ç›´æ¥è¯´äº‹ï¼Œåƒå‘ç»™æœ‹å‹çš„æ¶ˆæ¯ä¸€æ ·\n"
                    "- ç”¨ä¸­æ–‡"
                ),
            },
            {
                "role": "user",
                "content": f"ä»¥ä¸‹æ˜¯ä»Šæ—¥ Top 3 å†…å®¹ï¼ˆå·²æŒ‰é‡è¦æ€§æ’åºï¼‰ï¼š\n{top3_context}\n\nè¯·ç”Ÿæˆæ´å¯Ÿï¼š",
            },
        ]

        try:
            insight = self._get_client()._call_openai(history)
            return insight.strip() if insight else "ä»Šæ—¥ AI é¢†åŸŸæœ‰æ–°åŠ¨æ€å€¼å¾—å…³æ³¨ã€‚"
        except Exception as e:
            logger.warning(f"Failed to generate daily insight: {e}")
            return "ä»Šæ—¥ AI é¢†åŸŸæŒç»­æ´»è·ƒï¼Œå€¼å¾—å…³æ³¨ã€‚"

    def summarize_paper(self, title: str, abstract: str) -> str:
        """
        Generate a concise paper summary in Chinese.
        Token-efficient: keeps abstracts truncated and summaries brief.
        """
        # Truncate abstract to save tokens
        truncated = abstract[:800] if len(abstract) > 800 else abstract

        history = [
            {
                "role": "system",
                "content": (
                    "ä½ æ˜¯å­¦æœ¯è®ºæ–‡åŠ©æ‰‹ã€‚ç”¨ 1-2 å¥è¯æ¦‚æ‹¬è®ºæ–‡æ ¸å¿ƒè´¡çŒ®ã€‚\n"
                    "è§„åˆ™ï¼š\n"
                    "- æ§åˆ¶åœ¨ 60 å­—ä»¥å†…\n"
                    '- ç¬¬ä¸€å¥è¯´"åšäº†ä»€ä¹ˆ"ï¼Œç¬¬äºŒå¥è¯´"æ•ˆæœå¦‚ä½•"\n'
                    '- ä¸è¦ç”¨"æœ¬æ–‡""è¯¥ç ”ç©¶"ç­‰å­¦æœ¯å¥—è¯'
                ),
            },
            {
                "role": "user",
                "content": f"æ ‡é¢˜: {title}\n\næ‘˜è¦: {truncated}\n\nä¸€å¥è¯æ¦‚æ‹¬:",
            },
        ]

        try:
            summary = self._get_client()._call_openai(history)
            return summary.strip() if summary else ""
        except Exception as e:
            logger.warning(f"Failed to summarize paper: {e}")
            return ""

    def batch_summarize_papers(
        self, papers: list[dict[str, Any]]
    ) -> list[dict[str, Any]]:
        """
        Summarize multiple papers with rate limiting to control costs.
        Only summarize top papers to save tokens.
        """
        max_papers = 3  # Limit to save tokens
        results = []

        for i, paper in enumerate(papers[:max_papers]):
            logger.info(f"Summarizing paper {i+1}/{min(len(papers), max_papers)}")

            summary = self.summarize_paper(
                paper.get("title", ""), paper.get("abstract", "")
            )

            paper_copy = paper.copy()
            paper_copy["summary"] = summary
            results.append(paper_copy)

        # Add remaining papers without summary
        for paper in papers[max_papers:]:
            paper_copy = paper.copy()
            paper_copy["summary"] = ""
            results.append(paper_copy)

        return results

    def filter_by_keywords(
        self,
        items: list[ContentItem],
        keywords: dict[str, list[str]] | None = None,
        require_match: bool = True,
    ) -> list[ContentItem]:
        """
        Filter content items by keyword relevance.

        Args:
            items: List of ContentItem to filter
            keywords: Keyword categories (defaults to CONTENT_KEYWORDS config)
            require_match: If True, only return items matching keywords

        Returns:
            Filtered list of items
        """
        if keywords is None:
            keywords = CONTENT_KEYWORDS

        all_keywords = []
        for category_keywords in keywords.values():
            all_keywords.extend(category_keywords)

        filtered: list[ContentItem] = []
        for item in items:
            # Combine title and content for matching
            text = f"{item.title} {item.content} {item.summary}".lower()

            # Check if any keyword matches
            matches = any(kw.lower() in text for kw in all_keywords)

            if matches or not require_match:
                filtered.append(item)

        logger.info(f"Keyword filter: {len(filtered)}/{len(items)} items matched")
        return filtered

    def filter_by_engagement(
        self,
        items: list[ContentItem],
        min_score: int | None = None,
    ) -> list[ContentItem]:
        """
        Filter content items by engagement score.

        Args:
            items: List of ContentItem to filter
            min_score: Minimum engagement score (varies by source type)

        Returns:
            Filtered list of items
        """
        if min_score is None:
            # Default thresholds per source type
            min_score_by_type = {
                "twitter": 100,  # min likes + retweets*2
                "youtube": 10000,  # min views
                "blog": 0,
                "arxiv": 0,
            }
        else:
            min_score_by_type = {t: min_score for t in ["twitter", "youtube", "blog", "arxiv"]}

        filtered: list[ContentItem] = []
        for item in items:
            threshold = min_score_by_type.get(item.source_type, 0)
            if item.engagement_score >= threshold:
                filtered.append(item)

        logger.info(f"Engagement filter: {len(filtered)}/{len(items)} items passed")
        return filtered

    def generate_mixed_content_digest(
        self,
        papers: list[ContentItem],
        blogs: list[ContentItem],
        tweets: list[ContentItem],
        videos: list[ContentItem],
    ) -> str:
        """
        Generate a comprehensive daily digest from mixed content sources.

        Args:
            papers: ArXiv papers
            blogs: Blog posts
            tweets: Twitter content
            videos: YouTube videos

        Returns:
            Formatted digest string
        """
        sections = []

        # Papers section
        if papers:
            paper_titles = [p.title[:50] for p in papers[:3]]
            sections.append(f"ğŸ“„ è®ºæ–‡: {', '.join(paper_titles)}")

        # Blogs section
        if blogs:
            blog_titles = [b.title[:40] for b in blogs[:2]]
            sections.append(f"ğŸ“ åšå®¢: {', '.join(blog_titles)}")

        # Twitter section
        if tweets:
            top_tweet = tweets[0]
            sections.append(f"ğŸ¦ Twitter: @{top_tweet.source} åˆ†äº«çƒ­é—¨å†…å®¹")

        # YouTube section
        if videos:
            top_video = videos[0]
            sections.append(f"ğŸ“º è§†é¢‘: {top_video.title[:40]}...")

        if not sections:
            return "ä»Šæ—¥ AI é¢†åŸŸç¨³æ­¥å‘å±•ã€‚"

        context = "\n".join(sections)

        history = [
            {
                "role": "system",
                "content": (
                    "ä½ æ˜¯ AI æ™¨æŠ¥ç¼–è¾‘ã€‚åŸºäºä»¥ä¸‹ Top 3 å†…å®¹ç”Ÿæˆä»Šæ—¥æ´å¯Ÿï¼š\n\n"
                    "è§„åˆ™ï¼š\n"
                    "- æ€»å…±ä¸è¶…è¿‡ 80 å­—\n"
                    "- ç¬¬ä¸€å¥ç›´æ¥è¯´ä»Šå¤©æœ€é‡è¦çš„äº‹\n"
                    "- ä¸è¦ç½—åˆ—æ¯ä¸ªæºçš„å†…å®¹ï¼Œè€Œæ˜¯æç‚¼ä¸€ä¸ªæ ¸å¿ƒä¸»é¢˜\n"
                    "- åƒå‘ç»™æœ‹å‹çš„æ¶ˆæ¯ï¼Œä¸è¦ç”¨å¥—è¯"
                ),
            },
            {
                "role": "user",
                "content": f"ä»Šæ—¥ Top 3 å†…å®¹ï¼š\n{context}\n\nè¯·æç‚¼æ´å¯Ÿï¼š",
            },
        ]

        try:
            digest = self._get_client()._call_openai(history)
            return digest.strip() if digest else "ä»Šæ—¥ AI é¢†åŸŸæŒç»­æ´»è·ƒã€‚"
        except Exception as e:
            logger.warning(f"Failed to generate mixed digest: {e}")
            return "ä»Šæ—¥ AI é¢†åŸŸå¤šå…ƒå‘å±•ï¼Œå€¼å¾—å…³æ³¨ã€‚"

    def llm_relevance_check(
        self,
        item: ContentItem,
        topic: str = "AI/ML research and developments",
    ) -> bool:
        """
        Use LLM to check if content is relevant to specified topic.
        More accurate than keyword matching but costs tokens.

        Args:
            item: ContentItem to check
            topic: Topic to check relevance against

        Returns:
            True if relevant, False otherwise
        """
        # Skip LLM check for certain sources (too expensive)
        if item.source_type in ["twitter", "youtube"] and len(item.content) > 500:
            # Use keyword fallback for long social content
            return True

        content = item.content or item.summary or item.title
        if len(content) > 1000:
            content = content[:1000] + "..."

        history = [
            {
                "role": "system",
                "content": (
                    f"åˆ¤æ–­ä»¥ä¸‹å†…å®¹æ˜¯å¦ä¸ '{topic}' ç›¸å…³ã€‚\n"
                    "åªå›ç­” 'YES' æˆ– 'NO'ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"
                ),
            },
            {
                "role": "user",
                "content": f"æ ‡é¢˜: {item.title}\n\nå†…å®¹: {content}\n\nç›¸å…³å—ï¼Ÿ",
            },
        ]

        try:
            response = self._get_client()._call_openai(history)
            is_relevant: bool = bool(response and "YES" in response.upper())
            logger.debug(f"LLM relevance check for '{item.title[:30]}...': {is_relevant}")
            return is_relevant
        except Exception as e:
            logger.warning(f"LLM relevance check failed: {e}")
            # Default to keeping content if check fails
            return True
